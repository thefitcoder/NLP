{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does path exists :  True\n",
      "\n",
      "Does path exists in nltk :  True\n"
     ]
    }
   ],
   "source": [
    "import os, os.path \n",
    "  \n",
    "path = os.path.expanduser('~/nltk_data') \n",
    "  \n",
    "if not os.path.exists(path): \n",
    "    os.mkdir(path) \n",
    "      \n",
    "print (\"Does path exists : \", os.path.exists(path)) \n",
    "   \n",
    "import nltk.data \n",
    "print (\"\\nDoes path exists in nltk : \",  \n",
    "       path in nltk.data.path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.data.load('dtext.txt', format='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "file_docs = []\n",
    "\n",
    "tokens = sent_tokenize(text)\n",
    "for line in tokens:\n",
    "    file_docs.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "stemmerLan = LancasterStemmer()\n",
    "gen_docs = [[stemmerLan.stem(w.lower()) for w in word_tokenize(t)] \n",
    "            for t in file_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 0, 'a': 1, 'for': 2, 'goal': 3, 'it': 4, 'my': 5, 'odyssey—being': 6, 'on': 7, 'road': 8, 'the': 9, 'was': 10, 'year': 11, ',': 12, 'along': 13, 'beach': 14, 'coast': 15, 'eight': 16, 'i': 17, 'in': 18, 'mexcio': 19, 'month': 20, 'oaxac': 21, 'parad': 22, 'smal': 23, 'spend': 24, 'tim': 25, 'town': 26, 'airport': 27, 'al': 28, 'at': 29, 'being': 30, 'by': 31, 'challeng': 32, 'cop': 33, 'dealt': 34, 'fun': 35, 'had': 36, 'journey': 37, 'mexico—but': 38, 'me—backpack': 39, 'nev': 40, 'rob': 41, 'seattl': 42, 'stol': 43, 'stop': 44, 'threw': 45, 'travel': 46, 'with': 47, ':': 48, 'coronavir': 49, 'first': 50, 'novel': 51, 'resolv': 52, 'sor': 53, 'test': 54, 'accid': 55, 'adv': 56, 'an': 57, 'and': 58, 'becam': 59, 'expl': 60, 'impend': 61, 'less': 62, 'mor': 63, 'of': 64, 'world': 65, 'account': 66, 'back': 67, 'ban': 68, 'cross-continent': 69, 'fac': 70, 'get': 71, 'ind': 72, 'is': 73, 'marathon': 74, 'ov': 75, 'shutdown': 76, 'thi': 77, 'to': 78, 'try': 79, 'any': 80, 'as': 81, 'bar': 82, 'beer': 83, 'bef': 84, 'cancun': 85, 'dead': 86, 'ear': 87, 'febru': 88, 'from': 89, 'got': 90, 'me': 91, 'mex': 92, 'popul': 93, 'pun': 94, 'sil': 95, 'that': 96, 'too': 97, '15': 98, 'about': 99, 'america': 100, 'appl': 101, 'big': 102, 'broadway': 103, 'catch': 104, 'check': 105, 'cheesecak': 106, 'child': 107, 'creamy': 108, 'curs': 109, 'eileen': 110, 'ev': 111, 'flew': 112, 'front': 113, 'ful': 114, 'harry': 115, 'hel': 116, 'hit': 117, 'hous': 118, 'ita': 119, 'kitch': 120, 'list': 121, 'new': 122, 'newark': 123, 'not': 124, 'off': 125, 'out': 126, 'pag': 127, 'pot': 128, 'quintess': 129, 's': 130, 'saf': 131, 'spec': 132, 'stil': 133, 'thing': 134, 'went': 135, 'yet': 136, 'york': 137, '’': 138, '26': 139, 'anyon': 140, 'avoid': 141, 'between': 142, 'chinatown': 143, 'chines': 144, 'don': 145, 'east': 146, 'econom': 147, 'food': 148, 'hood': 149, 'impact': 150, 'kind': 151, 'most': 152, 'neg': 153, 'offset': 154, 'org': 155, 'soul': 156, 'through': 157, 'walk': 158, 'bacheloret': 159, 'city': 160, 'continu': 161, 'effort': 162, 'fest': 163, 'gra': 164, 'hop': 165, 'liv': 166, 'mard': 167, 'mus': 168, 'nashvil': 169, 'orl': 170, 'outdid': 171, 'pack': 172, 'party': 173, 'prevy': 174, 'ther': 175, 'unaffect': 176, 'venu': 177, 'wer': 178, 'wher': 179, '2': 180, 'america—the': 181, 'board': 182, 'covid-19': 183, 'death': 184, 'flight': 185, 'heard': 186, 'hour': 187, 'march': 188, 'nor': 189, 'ref': 190, 'sery': 191, 'stat': 192, 'washington': 193, 'concern': 194, 'despit': 195, 'just': 196, 'long': 197, 'nat': 198, 'no': 199, 'plan': 200, 'queu': 201, 'reag': 202, 'ronald': 203, 'sec': 204, 'seem': 205, '(': 206, ')': 207, 'ago': 208, 'cris': 209, 'cur': 210, 'feel': 211, 'giv': 212, 'lifetim': 213, 'lik': 214, '4': 215, ';': 216, 'already': 217, 'also': 218, 'annount': 219, 'becaus': 220, 'clos': 221, 'company': 222, 'employ': 223, 'hand': 224, 'hom': 225, 'howev': 226, 'posit': 227, 'run': 228, 'sanit': 229, 'school': 230, 'sev': 231, 'someon': 232, 'start': 233, 'stor': 234, 'their': 235, 'work': 236, 'abuzz': 237, 'ascend': 238, 'bellevu': 239, 'but': 240, 'empty': 241, 'flo': 242, 'mal': 243, 'rom': 244, 'shop': 245, 'top': 246, 'weekend': 247, '7': 248, 'francisco': 249, 'leav': 250, 'san': 251, 'uncharact': 252, 'when': 253, 'stroll': 254, 'mask': 255, 'or': 256, 'peopl': 257, 'sens': 258, 'temp': 259, 'half': 260, 'itself': 261, 'night': 262, 'saturday': 263, 'streets': 264, 'than': 265, 'though': 266, '9': 267, 'around': 268, 'folk': 269, 'mil': 270, 'monday': 271, 'plenty': 272, 'resum': 273, 'squ': 274, 'suit': 275, 'un': 276, 'up': 277, 'abs': 278, 'among': 279, 'both': 280, 'embarcadero': 281, 'hundr': 282, 'pal': 283, 'sou': 284, 'tour': 285, 'traff': 286, 'vehicul': 287, 'who': 288, 'ask': 289, 'caf': 290, 'corp': 291, 'day': 292, 'next': 293, 'quiet': 294, 'resta': 295, '14': 296, 'air': 297, 'couldn': 298, 'hano': 299, 'kor': 300, 'morn': 301, 'nerv': 302, 't': 303, 'uns': 304, 'airlin': 305, 'been': 306, 'cancel': 307, 'due': 308, 'forc': 309, 'restrict': 310, 'vietnam': 311, 'bal': 312, 'bought': 313, 'immedy': 314, 'singap': 315, 'ticket': 316, 'via': 317, 'although': 318, 'breez': 319, 'conduc': 320, 'decl': 321, 'emerg': 322, 'heal': 323, 'passeng': 324, 'screenings': 325, 'u.s.': 326, 'almost': 327, 'dist': 328, 'enough': 329, 'every': 330, 'flat': 331, 'lie': 332, 'pract': 333, 'room': 334, 'soc': 335, '17-hour': 336, 'beg': 337, 'could': 338, 'reliev': 339, 'a350': 340, 'clear': 341, 'cough': 342, 'insid': 343, 'look': 344, 'many': 345, 'shot': 346, 'sneez': 347, 'throat': 348, 'uncomfort': 349, 'wor': 350, 'follow': 351, 'land': 352, 'near': 353, 'we': 354, 'busy': 355, 'chang': 356, 'eat': 357, 'movy': 358, 'norm': 359, 'watch': 360, 'man': 361, 'numb': 362, 'screens': 363, 'therm': 364, 'tot': 365, 'behind': 366, 'hid': 367, 'passport': 368, 'scan': 369, 'smil': 370, 'stamp': 371, 'aft': 372, 'cousin': 373, 'onward': 374, '50': 375, 'backpack': 376, 'below': 377, 'capac': 378, 'cent': 379, 'europ': 380, 'fair': 381, 'per': 382, '16': 383, 'denpas': 384, 'fil': 385, 'form': 386, 'yellow': 387, 'auth': 388, 'everyon': 389, 'funct': 390, 'gav': 391, 'immigr': 392, 'process': 393, 'team': 394, 'took': 395, 'which': 396, 'part': 397, 'canggu': 398, 'hostel': 399, 'how': 400, 'lockdown': 401, 'nightfal': 402, 'talk': 403, 'going': 404, 'indones': 405, 'into': 406, 'murm': 407, 'soon': 408, '21': 409, 'airway': 410, 'freight': 411, 'kolkat': 412, 'myself': 413, 'tha': 414, 'train': 415, 'tuesday': 416, 'alon': 417, 'didn': 418, 'hotel': 419, 'interact': 420, 'rest': 421, 'seminyak': 422, 'spent': 423, 'ubud': 424, 'want': 425, '4.10': 426, 'bangkok': 427, 'four': 428, 'p.m.': 429, 'reach': 430, 'check-in': 431, 'hav': 432, 'overwhelm': 433, 'row': 434, 'saw': 435, 'ang': 436, 'cal': 437, 'car': 438, 'desp': 439, 'knew': 440, 'littl': 441, 'pass': 442, 'phon': 443, 'seen': 444, 'tear': 445, 'they': 446, 'two': 447, 'what': 448, 'anoth': 449, 'disembark': 450, 'fin': 451, 'leg': 452, 'suvarnabhum': 453, 'trip': 454, 'underw': 455, 'problem': 456, '1.30': 457, '12.30': 458, '22': 459, '23': 460, 'a.m.': 461, 'bos': 462, 'chandr': 463, 'intern': 464, 'last': 465, 'min': 466, 'netaj': 467, 'prob': 468, 'subhash': 469, 'sunday': 470, 'greet': 471, 'keep': 472, 'loud': 473, 'plead': 474, 'staff': 475, 'undergo': 476, 'whil': 477, 'self-reporting': 478, 'them': 479, 'away': 480, 'count': 481, 'feet': 482, 'interview': 483, 'lin': 484, 'stand': 485, 'us': 486, 'everyth': 487, 'felt': 488, 'bag': 489, 'reunit': 490, 'exit': 491, 'lock': 492, '2.30': 493, 'airport—our': 494, 'bus': 495, 'cant': 496, 'chittarand': 497, 'cisf': 498, 'dispos': 499, 'door': 500, 'each': 501, 'guid': 502, 'hazm': 503, 'history—before': 504, 'institut': 505, 'personnel': 506, 'prescrib': 507, 'quest': 508, 'research': 509, 'sam': 510, 'unlock': 511, 'writ': 512, 'asymptom': 513, 'pres': 514, 'read': 515, 'stabl': 516, 'vit': 517, '5.00': 518, 'quarantin': 519}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 0.11], ['for', 0.16], ['goal', 0.45], ['it', 0.25], ['my', 0.33], ['odyssey—being', 0.45], ['on', 0.1], ['road', 0.45], ['the', 0.04], ['was', 0.22], ['year', 0.37]]\n",
      "[['the', 0.03], ['was', 0.07], [',', 0.08], ['along', 0.26], ['beach', 0.23], ['coast', 0.23], ['eight', 0.26], ['i', 0.07], ['in', 0.33], ['mexcio', 0.31], ['month', 0.31], ['oaxac', 0.31], ['parad', 0.31], ['smal', 0.31], ['spend', 0.26], ['tim', 0.23], ['town', 0.23]]\n",
      "[['the', 0.04], [',', 0.02], ['i', 0.05], ['in', 0.06], ['airport', 0.08], ['al', 0.09], ['at', 0.15], ['being', 0.62], ['by', 0.11], ['challeng', 0.21], ['cop', 0.21], ['dealt', 0.21], ['fun', 0.21], ['had', 0.08], ['journey', 0.17], ['mexico—but', 0.21], ['me—backpack', 0.21], ['nev', 0.21], ['rob', 0.21], ['seattl', 0.14], ['stol', 0.21], ['stop', 0.21], ['threw', 0.21], ['travel', 0.11], ['with', 0.12]]\n",
      "[['for', 0.15], ['my', 0.15], ['the', 0.07], ['was', 0.1], [',', 0.04], ['tim', 0.3], ['by', 0.22], [':', 0.25], ['coronavir', 0.25], ['first', 0.34], ['novel', 0.34], ['resolv', 0.41], ['sor', 0.41], ['test', 0.3]]\n",
      "[['the', 0.03], ['accid', 0.34], ['adv', 0.25], ['an', 0.49], ['and', 0.06], ['becam', 0.34], ['expl', 0.34], ['impend', 0.34], ['less', 0.28], ['mor', 0.25], ['of', 0.18], ['world', 0.25]]\n",
      "[['a', 0.07], ['my', 0.11], ['the', 0.05], ['in', 0.08], ['and', 0.06], ['of', 0.16], ['world', 0.22], ['account', 0.3], ['back', 0.2], ['ban', 0.25], ['cross-continent', 0.3], ['fac', 0.25], ['get', 0.22], ['ind', 0.25], ['is', 0.3], ['marathon', 0.3], ['ov', 0.22], ['shutdown', 0.3], ['thi', 0.18], ['to', 0.11], ['try', 0.25]]\n",
      "[['a', 0.13], ['it', 0.15], ['on', 0.06], ['the', 0.05], ['was', 0.06], [',', 0.02], ['in', 0.07], ['at', 0.1], ['coronavir', 0.16], ['novel', 0.22], ['any', 0.27], ['as', 0.18], ['bar', 0.18], ['beer', 0.27], ['bef', 0.22], ['cancun', 0.22], ['dead', 0.27], ['ear', 0.19], ['febru', 0.19], ['from', 0.13], ['got', 0.19], ['me', 0.19], ['mex', 0.27], ['popul', 0.22], ['pun', 0.27], ['sil', 0.27], ['that', 0.13], ['too', 0.19]]\n",
      "[['a', 0.07], ['on', 0.04], ['the', 0.06], [',', 0.04], ['i', 0.04], ['in', 0.04], ['at', 0.11], ['travel', 0.08], ['with', 0.09], [':', 0.09], ['and', 0.14], ['of', 0.04], ['to', 0.05], ['cancun', 0.13], ['febru', 0.11], ['from', 0.08], ['15', 0.11], ['about', 0.09], ['america', 0.15], ['appl', 0.15], ['big', 0.15], ['broadway', 0.15], ['catch', 0.13], ['check', 0.08], ['cheesecak', 0.31], ['child', 0.15], ['creamy', 0.15], ['curs', 0.15], ['eileen', 0.15], ['ev', 0.1], ['flew', 0.15], ['front', 0.15], ['ful', 0.13], ['harry', 0.15], ['hel', 0.15], ['hit', 0.13], ['hous', 0.13], ['ita', 0.15], ['kitch', 0.15], ['list', 0.15], ['new', 0.17], ['newark', 0.15], ['not', 0.11], ['off', 0.13], ['out', 0.1], ['pag', 0.15], ['pot', 0.15], ['quintess', 0.15], ['s', 0.16], ['saf', 0.15], ['spec', 0.15], ['stil', 0.09], ['thing', 0.15], ['went', 0.13], ['yet', 0.11], ['york', 0.11], ['’', 0.14]]\n",
      "[['a', 0.09], ['on', 0.05], ['the', 0.07], ['was', 0.05], [',', 0.02], ['coast', 0.14], ['by', 0.1], ['had', 0.07], ['coronavir', 0.12], ['and', 0.04], ['of', 0.05], ['to', 0.03], ['febru', 0.14], ['from', 0.1], ['that', 0.1], ['15', 0.14], ['about', 0.12], ['new', 0.11], ['york', 0.14], ['26', 0.2], ['anyon', 0.2], ['avoid', 0.2], ['between', 0.16], ['chinatown', 0.2], ['chines', 0.2], ['don', 0.2], ['east', 0.16], ['econom', 0.2], ['food', 0.39], ['hood', 0.2], ['impact', 0.16], ['kind', 0.2], ['most', 0.13], ['neg', 0.2], ['offset', 0.2], ['org', 0.2], ['soul', 0.2], ['through', 0.2], ['walk', 0.2]]\n",
      "[['the', 0.05], ['year', 0.16], [',', 0.07], ['i', 0.05], ['in', 0.05], ['al', 0.08], ['and', 0.07], ['to', 0.07], ['from', 0.1], ['new', 0.11], ['s', 0.1], ['’', 0.09], ['bacheloret', 0.2], ['city', 0.16], ['continu', 0.2], ['effort', 0.2], ['fest', 0.2], ['gra', 0.2], ['hop', 0.2], ['liv', 0.2], ['mard', 0.2], ['mus', 0.39], ['nashvil', 0.2], ['orl', 0.2], ['outdid', 0.2], ['pack', 0.16], ['party', 0.2], ['prevy', 0.2], ['ther', 0.11], ['unaffect', 0.16], ['venu', 0.2], ['wer', 0.08], ['wher', 0.33]]\n",
      "[['a', 0.07], ['on', 0.06], ['the', 0.02], [',', 0.05], ['i', 0.06], ['in', 0.15], ['seattl', 0.18], ['first', 0.23], ['to', 0.1], ['bef', 0.23], ['2', 0.27], ['america—the', 0.27], ['board', 0.2], ['covid-19', 0.27], ['death', 0.27], ['flight', 0.1], ['heard', 0.27], ['hour', 0.17], ['march', 0.12], ['nor', 0.27], ['ref', 0.27], ['sery', 0.27], ['stat', 0.27], ['washington', 0.23]]\n",
      "[['on', 0.12], ['the', 0.05], [',', 0.05], ['coast', 0.19], ['airport', 0.1], ['at', 0.19], ['coronavir', 0.16], ['and', 0.05], ['that', 0.13], ['about', 0.16], ['check', 0.14], ['yet', 0.19], ['east', 0.22], ['pack', 0.22], ['wer', 0.1], ['washington', 0.22], ['concern', 0.26], ['despit', 0.22], ['just', 0.26], ['long', 0.26], ['nat', 0.17], ['no', 0.17], ['plan', 0.26], ['queu', 0.22], ['reag', 0.26], ['ronald', 0.26], ['sec', 0.19], ['seem', 0.19]]\n",
      "[['a', 0.08], [',', 0.03], ['thi', 0.19], ['new', 0.18], ['s', 0.17], ['york', 0.23], ['’', 0.15], ['(', 0.32], [')', 0.32], ['ago', 0.32], ['cris', 0.32], ['cur', 0.32], ['feel', 0.26], ['giv', 0.32], ['lifetim', 0.32], ['lik', 0.23]]\n",
      "[['on', 0.05], ['the', 0.02], ['was', 0.05], [',', 0.05], ['in', 0.11], ['by', 0.1], ['had', 0.22], ['seattl', 0.13], ['test', 0.15], ['adv', 0.15], ['and', 0.04], ['of', 0.05], ['to', 0.03], ['from', 0.1], ['out', 0.13], ['march', 0.09], ['4', 0.2], [';', 0.17], ['already', 0.2], ['also', 0.17], ['annount', 0.2], ['becaus', 0.2], ['clos', 0.2], ['company', 0.2], ['employ', 0.17], ['hand', 0.15], ['hom', 0.1], ['howev', 0.17], ['posit', 0.2], ['run', 0.17], ['sanit', 0.2], ['school', 0.4], ['sev', 0.2], ['someon', 0.17], ['start', 0.2], ['stor', 0.2], ['their', 0.12], ['work', 0.11]]\n",
      "[['on', 0.11], ['the', 0.09], ['was', 0.12], [',', 0.09], ['by', 0.13], ['of', 0.13], ['bar', 0.16], ['popul', 0.2], ['s', 0.13], ['stil', 0.14], ['’', 0.11], ['most', 0.16], ['city', 0.2], ['abuzz', 0.24], ['ascend', 0.24], ['bellevu', 0.24], ['but', 0.13], ['empty', 0.16], ['flo', 0.24], ['mal', 0.49], ['rom', 0.24], ['shop', 0.2], ['top', 0.24], ['weekend', 0.24]]\n",
      "[['for', 0.14], ['on', 0.09], ['was', 0.19], [',', 0.1], ['i', 0.09], ['airport', 0.15], ['seattl', 0.26], ['march', 0.17], ['howev', 0.32], ['empty', 0.26], ['7', 0.39], ['francisco', 0.28], ['leav', 0.32], ['san', 0.28], ['uncharact', 0.39], ['when', 0.26]]\n",
      "[['a', 0.19], ['was', 0.19], ['sec', 0.57], ['stroll', 0.78]]\n",
      "[[',', 0.04], ['in', 0.12], ['test', 0.32], ['mor', 0.32], ['stil', 0.25], ['ther', 0.25], ['wer', 0.17], ['no', 0.29], ['but', 0.23], ['mask', 0.29], ['or', 0.36], ['peopl', 0.27], ['sens', 0.36], ['temp', 0.27]]\n",
      "[['a', 0.07], ['it', 0.15], ['the', 0.05], ['was', 0.13], [',', 0.02], ['in', 0.07], ['and', 0.1], ['less', 0.23], ['to', 0.05], ['bar', 0.18], ['ful', 0.23], ['wer', 0.11], ['flight', 0.1], ['empty', 0.18], ['francisco', 0.4], ['san', 0.4], ['half', 0.27], ['itself', 0.27], ['night', 0.23], ['saturday', 0.2], ['streets', 0.27], ['than', 0.23], ['though', 0.27]]\n",
      "[['on', 0.06], [',', 0.07], ['of', 0.07], ['from', 0.13], ['about', 0.16], ['ther', 0.15], ['wer', 0.21], ['march', 0.12], ['hom', 0.14], ['work', 0.3], ['but', 0.14], ['when', 0.17], ['peopl', 0.16], ['9', 0.26], ['around', 0.22], ['folk', 0.26], ['mil', 0.26], ['monday', 0.22], ['plenty', 0.26], ['resum', 0.26], ['squ', 0.26], ['suit', 0.22], ['un', 0.26], ['up', 0.22]]\n",
      "[['my', 0.09], ['the', 0.07], [',', 0.02], ['along', 0.21], ['beach', 0.18], ['i', 0.06], ['in', 0.07], ['and', 0.09], ['that', 0.12], ['ev', 0.17], ['not', 0.18], ['wer', 0.29], ['run', 0.21], ['but', 0.13], ['abs', 0.25], ['among', 0.25], ['both', 0.25], ['embarcadero', 0.25], ['hundr', 0.25], ['pal', 0.25], ['sou', 0.25], ['tour', 0.25], ['traff', 0.25], ['vehicul', 0.25], ['who', 0.21]]\n",
      "[['the', 0.06], [',', 0.06], ['al', 0.14], ['had', 0.13], ['and', 0.13], ['to', 0.06], ['bar', 0.23], ['from', 0.17], ['wer', 0.14], ['employ', 0.29], ['hom', 0.18], ['their', 0.21], ['work', 0.19], ['ask', 0.25], ['caf', 0.35], ['corp', 0.35], ['day', 0.23], ['next', 0.29], ['quiet', 0.29], ['resta', 0.35]]\n",
      "[['for', 0.1], ['my', 0.1], ['on', 0.07], [',', 0.08], ['i', 0.13], ['in', 0.07], ['airport', 0.11], ['and', 0.05], ['to', 0.15], ['check', 0.15], ['went', 0.23], ['’', 0.13], ['flight', 0.1], ['march', 0.12], ['but', 0.15], ['francisco', 0.21], ['san', 0.21], ['saturday', 0.21], ['14', 0.23], ['air', 0.28], ['couldn', 0.28], ['hano', 0.28], ['kor', 0.28], ['morn', 0.23], ['nerv', 0.28], ['t', 0.23], ['uns', 0.28]]\n",
      "[['it', 0.2], ['the', 0.03], ['had', 0.13], ['travel', 0.19], ['of', 0.09], ['to', 0.12], ['new', 0.2], ['most', 0.24], ['flight', 0.13], ['airlin', 0.26], ['been', 0.26], ['cancel', 0.36], ['due', 0.36], ['forc', 0.36], ['restrict', 0.36], ['vietnam', 0.36]]\n",
      "[['a', 0.11], ['i', 0.11], ['to', 0.08], ['bal', 0.39], ['bought', 0.39], ['immedy', 0.46], ['singap', 0.31], ['ticket', 0.39], ['via', 0.46]]\n",
      "[['a', 0.15], ['for', 0.11], ['the', 0.06], [',', 0.06], ['airport', 0.12], ['had', 0.12], ['and', 0.06], ['check', 0.17], ['wer', 0.12], ['nat', 0.21], ['no', 0.21], ['sec', 0.23], ['although', 0.32], ['breez', 0.26], ['conduc', 0.32], ['decl', 0.32], ['emerg', 0.32], ['heal', 0.18], ['passeng', 0.17], ['screenings', 0.32], ['u.s.', 0.32]]\n",
      "[['for', 0.12], ['on', 0.08], ['the', 0.03], ['was', 0.08], [',', 0.03], ['i', 0.08], ['had', 0.12], ['and', 0.06], ['to', 0.06], ['flight', 0.12], ['airlin', 0.24], ['singap', 0.22], ['passeng', 0.17], ['almost', 0.33], ['dist', 0.22], ['enough', 0.33], ['every', 0.27], ['flat', 0.33], ['lie', 0.33], ['pract', 0.33], ['room', 0.27], ['soc', 0.27]]\n",
      "[['the', 0.11], ['i', 0.1], ['in', 0.11], ['journey', 0.34], ['to', 0.07], ['as', 0.27], ['flight', 0.15], ['feel', 0.34], ['singap', 0.27], ['17-hour', 0.41], ['beg', 0.3], ['could', 0.41], ['reliev', 0.34]]\n",
      "[['the', 0.02], [',', 0.05], ['tim', 0.19], ['al', 0.11], ['and', 0.05], ['ther', 0.15], ['wer', 0.1], ['someon', 0.22], ['their', 0.16], ['mask', 0.17], ['or', 0.22], ['around', 0.22], ['every', 0.22], ['a350', 0.26], ['clear', 0.19], ['cough', 0.26], ['insid', 0.22], ['look', 0.26], ['many', 0.22], ['shot', 0.26], ['sneez', 0.26], ['throat', 0.26], ['uncomfort', 0.26], ['wor', 0.26]]\n",
      "[['on', 0.09], ['the', 0.04], ['in', 0.11], ['an', 0.29], ['ear', 0.29], ['15', 0.29], ['ev', 0.26], ['hour', 0.24], ['march', 0.17], ['singap', 0.26], ['follow', 0.4], ['land', 0.29], ['near', 0.4], ['we', 0.33]]\n",
      "[['a', 0.07], ['was', 0.07], [',', 0.11], ['town', 0.22], ['airport', 0.12], ['with', 0.17], ['and', 0.05], ['to', 0.05], ['try', 0.25], ['catch', 0.25], ['out', 0.2], ['between', 0.25], ['flight', 0.11], ['work', 0.17], ['shop', 0.25], ['quiet', 0.25], ['passeng', 0.16], ['busy', 0.3], ['chang', 0.25], ['eat', 0.3], ['movy', 0.3], ['norm', 0.25], ['watch', 0.3]]\n",
      "[['it', 0.17], ['the', 0.05], ['airport', 0.12], ['at', 0.11], ['mor', 0.22], ['of', 0.08], ['that', 0.15], ['ev', 0.2], ['ther', 0.34], ['wer', 0.12], ['seem', 0.22], ['lik', 0.22], ['peopl', 0.18], ['sens', 0.25], ['than', 0.25], ['passeng', 0.16], ['man', 0.3], ['numb', 0.25], ['screens', 0.3], ['therm', 0.3], ['tot', 0.3]]\n",
      "[['a', 0.15], ['my', 0.12], [',', 0.06], ['i', 0.07], ['with', 0.18], ['and', 0.06], ['got', 0.47], ['not', 0.23], ['mask', 0.21], ['clear', 0.23], ['behind', 0.26], ['hid', 0.32], ['passport', 0.26], ['scan', 0.32], ['smil', 0.32], ['stamp', 0.32]]\n",
      "[['for', 0.12], ['my', 0.24], ['the', 0.06], ['was', 0.08], [',', 0.03], ['i', 0.08], ['spend', 0.27], ['airport', 0.13], ['at', 0.24], ['back', 0.22], ['to', 0.06], ['hous', 0.27], ['s', 0.17], ['stil', 0.19], ['’', 0.15], ['flight', 0.12], ['empty', 0.22], ['night', 0.27], ['bal', 0.27], ['chang', 0.27], ['aft', 0.2], ['cousin', 0.33], ['onward', 0.33]]\n",
      "[['a', 0.08], ['the', 0.03], ['was', 0.08], [',', 0.03], ['travel', 0.17], ['and', 0.06], ['of', 0.08], ['stil', 0.18], ['flight', 0.12], ['despit', 0.26], ['numb', 0.26], ['50', 0.32], ['backpack', 0.32], ['below', 0.32], ['capac', 0.32], ['cent', 0.32], ['europ', 0.32], ['fair', 0.32], ['per', 0.26]]\n",
      "[['a', 0.08], ['on', 0.08], [',', 0.09], ['i', 0.08], ['in', 0.09], ['al', 0.14], ['had', 0.13], ['travel', 0.18], ['to', 0.06], ['march', 0.15], ['when', 0.23], ['monday', 0.29], ['up', 0.29], ['heal', 0.2], ['land', 0.26], ['16', 0.35], ['denpas', 0.35], ['fil', 0.35], ['form', 0.29], ['yellow', 0.29]]\n",
      "[['a', 0.06], ['for', 0.09], ['the', 0.04], ['was', 0.12], [',', 0.02], ['al', 0.1], ['and', 0.05], ['of', 0.13], ['ov', 0.18], ['thi', 0.15], ['to', 0.13], ['as', 0.17], ['s', 0.13], ['stil', 0.14], ['’', 0.12], ['most', 0.17], ['nat', 0.17], ['hand', 0.18], ['work', 0.14], ['peopl', 0.15], ['temp', 0.15], ['heal', 0.14], ['clear', 0.18], ['norm', 0.21], ['aft', 0.15], ['per', 0.21], ['auth', 0.25], ['everyon', 0.18], ['funct', 0.25], ['gav', 0.25], ['immigr', 0.21], ['process', 0.25], ['team', 0.25], ['took', 0.18], ['which', 0.21]]\n",
      "[['a', 0.11], ['the', 0.04], ['was', 0.11], [',', 0.04], ['and', 0.08], ['of', 0.12], ['world', 0.32], ['thi', 0.26], ['to', 0.08], ['me', 0.32], ['that', 0.21], ['unaffect', 0.36], ['seem', 0.32], ['day', 0.29], ['breez', 0.36], ['part', 0.43]]\n",
      "[['my', 0.11], ['the', 0.03], ['was', 0.07], [',', 0.05], ['beach', 0.21], ['in', 0.08], ['al', 0.12], ['at', 0.11], ['by', 0.15], ['and', 0.05], ['of', 0.08], ['back', 0.38], ['get', 0.21], ['to', 0.05], ['from', 0.14], ['got', 0.21], ['hom', 0.15], ['but', 0.15], ['when', 0.19], ['everyon', 0.21], ['canggu', 0.29], ['hostel', 0.29], ['how', 0.29], ['lockdown', 0.24], ['nightfal', 0.29], ['talk', 0.29]]\n",
      "[['a', 0.09], ['of', 0.1], ['ther', 0.22], ['wer', 0.15], ['also', 0.32], ['lockdown', 0.32], ['going', 0.32], ['indones', 0.39], ['into', 0.39], ['murm', 0.39], ['soon', 0.39]]\n",
      "[['a', 0.13], ['for', 0.1], ['on', 0.13], ['the', 0.02], [',', 0.05], ['i', 0.06], ['coronavir', 0.16], ['and', 0.05], ['of', 0.07], ['to', 0.05], ['me', 0.2], ['hit', 0.23], ['impact', 0.23], ['march', 0.12], ['lik', 0.2], ['morn', 0.23], ['bought', 0.23], ['ticket', 0.23], ['21', 0.27], ['airway', 0.27], ['freight', 0.27], ['kolkat', 0.23], ['myself', 0.27], ['tha', 0.27], ['train', 0.27], ['tuesday', 0.27]]\n",
      "[['the', 0.05], ['i', 0.12], ['in', 0.14], ['with', 0.15], ['and', 0.05], ['of', 0.07], ['to', 0.05], ['as', 0.18], ['too', 0.2], ['’', 0.12], ['peopl', 0.16], ['day', 0.18], ['t', 0.22], ['room', 0.22], ['many', 0.22], ['alon', 0.27], ['didn', 0.27], ['hotel', 0.27], ['interact', 0.27], ['rest', 0.27], ['seminyak', 0.27], ['spent', 0.27], ['ubud', 0.27], ['want', 0.27]]\n",
      "[['for', 0.14], ['my', 0.14], ['on', 0.09], ['the', 0.03], [',', 0.03], ['i', 0.09], ['airport', 0.15], ['to', 0.07], ['ear', 0.28], ['flight', 0.14], ['hour', 0.23], ['saturday', 0.28], ['4.10', 0.38], ['bangkok', 0.32], ['four', 0.38], ['p.m.', 0.38], ['reach', 0.38]]\n",
      "[['my', 0.13], ['the', 0.09], [',', 0.03], ['i', 0.08], ['at', 0.13], ['had', 0.13], ['too', 0.25], ['check', 0.18], ['queu', 0.29], ['temp', 0.21], ['next', 0.29], ['aft', 0.21], ['check-in', 0.34], ['hav', 0.34], ['overwhelm', 0.34], ['row', 0.34], ['saw', 0.34]]\n",
      "[['it', 0.12], ['my', 0.08], ['on', 0.1], ['the', 0.02], ['was', 0.1], [',', 0.07], ['i', 0.05], ['in', 0.06], ['al', 0.09], ['had', 0.08], ['travel', 0.11], ['and', 0.08], ['of', 0.06], ['back', 0.14], ['fac', 0.17], ['get', 0.3], ['to', 0.04], ['that', 0.1], ['about', 0.25], ['board', 0.15], ['hour', 0.13], ['hom', 0.11], ['who', 0.17], ['reliev', 0.17], ['took', 0.15], ['going', 0.17], ['ang', 0.21], ['cal', 0.21], ['car', 0.21], ['desp', 0.21], ['knew', 0.21], ['littl', 0.21], ['pass', 0.21], ['phon', 0.21], ['seen', 0.21], ['tear', 0.21], ['they', 0.21], ['two', 0.14], ['what', 0.21]]\n",
      "[['a', 0.07], ['for', 0.11], ['my', 0.11], ['the', 0.05], [',', 0.03], ['i', 0.07], ['in', 0.08], ['airport', 0.12], ['at', 0.11], ['and', 0.05], ['of', 0.08], ['to', 0.05], ['check', 0.16], ['yet', 0.22], ['board', 0.22], ['flight', 0.11], ['temp', 0.18], ['aft', 0.18], ['kolkat', 0.25], ['bangkok', 0.25], ['anoth', 0.3], ['disembark', 0.3], ['fin', 0.25], ['leg', 0.3], ['suvarnabhum', 0.3], ['trip', 0.3], ['underw', 0.3]]\n",
      "[['a', 0.1], ['on', 0.19], ['was', 0.1], ['al', 0.34], ['at', 0.15], ['had', 0.15], ['and', 0.08], ['thi', 0.25], ['flight', 0.15], ['no', 0.27], ['but', 0.22], ['mask', 0.27], ['passeng', 0.22], ['dist', 0.27], ['soc', 0.34], ['two', 0.27], ['problem', 0.42]]\n",
      "[['on', 0.17], ['the', 0.02], ['was', 0.04], [',', 0.03], ['airport', 0.07], ['at', 0.14], ['of', 0.05], ['ban', 0.15], ['ind', 0.15], ['to', 0.03], ['s', 0.1], ['’', 0.09], ['flight', 0.14], ['march', 0.16], [';', 0.15], ['beg', 0.14], ['land', 0.14], ['1.30', 0.19], ['12.30', 0.19], ['22', 0.15], ['23', 0.19], ['a.m.', 0.27], ['bos', 0.19], ['chandr', 0.19], ['intern', 0.56], ['last', 0.19], ['min', 0.15], ['netaj', 0.19], ['prob', 0.19], ['subhash', 0.19], ['sunday', 0.19]]\n",
      "[['the', 0.03], [',', 0.03], ['al', 0.13], ['by', 0.16], ['to', 0.05], ['check', 0.16], ['wer', 0.12], ['their', 0.19], ['temp', 0.19], ['heal', 0.18], ['passeng', 0.16], ['dist', 0.21], ['insid', 0.26], ['greet', 0.32], ['keep', 0.32], ['loud', 0.32], ['plead', 0.32], ['staff', 0.26], ['undergo', 0.32], ['whil', 0.32]]\n",
      "[['on', 0.11], ['the', 0.04], ['i', 0.11], ['of', 0.12], ['ov', 0.34], ['to', 0.08], ['hand', 0.34], ['heal', 0.26], ['form', 0.38], ['two', 0.3], ['self-reporting', 0.46], ['them', 0.46]]\n",
      "[['for', 0.1], ['on', 0.06], ['the', 0.1], ['eight', 0.23], ['and', 0.05], ['to', 0.05], ['off', 0.23], ['their', 0.17], ['leav', 0.23], ['ask', 0.2], ['behind', 0.23], ['passport', 0.23], ['yellow', 0.23], ['immigr', 0.23], ['away', 0.28], ['count', 0.28], ['feet', 0.28], ['interview', 0.28], ['lin', 0.28], ['stand', 0.28], ['us', 0.23]]\n",
      "[['and', 0.11], ['dist', 0.38], ['everyon', 0.42], ['everyth', 0.58], ['felt', 0.58]]\n",
      "[['my', 0.19], ['was', 0.12], [',', 0.05], ['i', 0.12], ['with', 0.29], ['an', 0.37], ['hour', 0.31], ['aft', 0.31], ['bag', 0.51], ['reunit', 0.51]]\n",
      "[['the', 0.05], ['airport', 0.23], ['had', 0.22], ['been', 0.43], ['exit', 0.59], ['lock', 0.59]]\n",
      "[['a', 0.04], ['for', 0.06], ['on', 0.04], ['the', 0.09], [',', 0.01], ['in', 0.09], ['town', 0.12], ['al', 0.07], ['at', 0.12], ['had', 0.06], ['travel', 0.09], ['and', 0.06], ['to', 0.06], ['that', 0.16], ['new', 0.09], ['out', 0.11], ['wher', 0.14], ['nat', 0.11], ['work', 0.09], ['suit', 0.14], ['ask', 0.24], ['airlin', 0.12], ['been', 0.12], ['heal', 0.18], ['passeng', 0.09], ['we', 0.14], ['took', 0.12], ['two', 0.11], ['a.m.', 0.12], ['staff', 0.14], ['us', 0.27], ['2.30', 0.16], ['airport—our', 0.16], ['bus', 0.16], ['cant', 0.16], ['chittarand', 0.16], ['cisf', 0.16], ['dispos', 0.16], ['door', 0.16], ['each', 0.16], ['guid', 0.16], ['hazm', 0.16], ['history—before', 0.16], ['institut', 0.16], ['personnel', 0.16], ['prescrib', 0.16], ['quest', 0.16], ['research', 0.16], ['sam', 0.16], ['unlock', 0.16], ['writ', 0.16]]\n",
      "[[':', 0.53], ['min', 0.37], ['asymptom', 0.44], ['pres', 0.44], ['read', 0.44]]\n",
      "[[':', 0.39], ['stabl', 0.65], ['vit', 0.65]]\n",
      "[['for', 0.13], ['on', 0.09], [',', 0.03], ['at', 0.14], [':', 0.22], ['adv', 0.27], ['march', 0.16], ['hom', 0.19], ['day', 0.25], ['14', 0.31], ['beg', 0.27], ['which', 0.31], ['22', 0.31], ['a.m.', 0.27], ['5.00', 0.37], ['quarantin', 0.37]]\n",
      "[['was', 0.23], [',', 0.17], ['i', 0.22], ['hom', 0.5], ['fin', 0.79]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "for doc in tf_idf[corpus]:\n",
    "    print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = gensim.similarities.Similarity('~/',tf_idf[corpus],\n",
    "                                        num_features=len(dictionary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtext = nltk.data.load('ScrapedArticles1.txt', format='raw')\n",
    "dtext = dtext.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2_docs = []\n",
    "\n",
    "\n",
    "tokens = sent_tokenize(dtext)\n",
    "for line in tokens:\n",
    "    file2_docs.append(line)\n",
    "\n",
    "\n",
    "for line in file2_docs:\n",
    "    query_doc = [stemmerLan.stem(w.lower()) for w in word_tokenize(line)]\n",
    "    query_doc_bow = dictionary.doc2bow(query_doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc_tf_idf = tf_idf[query_doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Result: [0.08397658 0.00280307 0.00377832 0.00754234 0.00307381 0.17836769\n",
      " 0.08922999 0.09128016 0.03387509 0.05999117 0.00248938 0.04025149\n",
      " 0.08771817 0.00181435 0.07673094 0.         0.         0.\n",
      " 0.05354299 0.         0.04115685 0.00629116 0.03421503 0.06710781\n",
      " 0.         0.00579258 0.00296692 0.01129084 0.0023702  0.00359856\n",
      " 0.         0.10039233 0.         0.09750519 0.00287084 0.\n",
      " 0.07422836 0.06352726 0.00264552 0.22103387 0.00246923 0.03724965\n",
      " 0.00347923 0.00937513 0.06762796 0.00543646 0.         0.05299088\n",
      " 0.00286796 0.0041839  0.01017225 0.         0.         0.00540249\n",
      " 0.05405626 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('Comparing Result:', sims[query_doc_tf_idf]) # Displaying s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity rounded percentage: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "avg_sims = []\n",
    "for line in file2_docs:\n",
    "        query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "        query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "        query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "        sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float32))\n",
    "        avg = sum_of_sims / len(file_docs)\n",
    "        avg_sims.append(avg)  \n",
    "\n",
    "total_avg = np.sum(avg_sims, dtype=np.float)/ len(avg_sims)\n",
    "percentage_of_similarity = round(float(total_avg) * 100)\n",
    "print(f'Average similarity rounded percentage: {percentage_of_similarity}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
